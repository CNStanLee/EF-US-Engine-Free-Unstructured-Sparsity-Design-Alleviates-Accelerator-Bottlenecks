{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4acafe09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/changhong/prj/finn/notebooks\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ab14961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from brevitas.nn import QuantConv2d, QuantLinear, QuantReLU, QuantIdentity\n",
    "from brevitas.quant import Int8WeightPerTensorFixedPoint, Int8ActPerTensorFixedPoint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import onnx\n",
    "from finn.util.test import get_test_model_trained\n",
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from finn.util.basic import make_build_dir\n",
    "from finn.util.visualization import showInNetron\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "88cc3a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 18 16:55:10 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX 4000 Ada Gene...    Off |   00000000:02:00.0  On |                  Off |\n",
      "| 30%   32C    P8             11W /  130W |    5453MiB /  20475MiB |     43%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "48297cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/changhong/prj/finn/notebooks\n"
     ]
    }
   ],
   "source": [
    "# print current working directory\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5cc6c845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /home/changhong/prj/finn/notebooks/EF-US-Engine-Free-Unstructured-Sparsity-Design-Alleviates-Accelerator-Bottlenecks/casestudy1/LeNet_MNIST/data\n",
      "Finn root directory: /home/changhong/prj/finn/notebooks\n",
      "Build directory: /home/changhong/prj/finn/notebooks/EF-US-Engine-Free-Unstructured-Sparsity-Design-Alleviates-Accelerator-Bottlenecks/casestudy1/LeNet_MNIST/build\n",
      "Model directory: /home/changhong/prj/finn/notebooks/EF-US-Engine-Free-Unstructured-Sparsity-Design-Alleviates-Accelerator-Bottlenecks/casestudy1/LeNet_MNIST/model\n"
     ]
    }
   ],
   "source": [
    "notebook_name = \"/EF-US-Engine-Free-Unstructured-Sparsity-Design-Alleviates-Accelerator-Bottlenecks/casestudy1/LeNet_MNIST\"\n",
    "finn_root = os.getcwd()\n",
    "build_dir = finn_root+ notebook_name +\"/build\"\n",
    "model_dir = finn_root+ notebook_name +\"/model\"\n",
    "data_dir = finn_root+ notebook_name +\"/data\"\n",
    "\n",
    "# Create directories if they do not exist\n",
    "os.makedirs(build_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Finn root directory: {finn_root}\")\n",
    "print(f\"Build directory: {build_dir}\")\n",
    "print(f\"Model directory: {model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3fa7b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS = 50\n",
    "LR = 0.001\n",
    "BATACH_SIZE = 128\n",
    "RANDOM_SEED = 1998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "91a07d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split complete:\n",
      "Training set: 50000 samples\n",
      "Validation set: 10000 samples\n",
      "Test set: 10000 samples\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "\n",
    "# Define data transformations\n",
    "# Normalize using MNIST mean (0.1307) and std deviation (0.3081)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Load full MNIST training set (60,000 samples)\n",
    "full_train_dataset = torchvision.datasets.MNIST(\n",
    "    root=data_dir,\n",
    "    train=True,       # Load training set (not test set)\n",
    "    download=True,    # Download if not exists\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Standard academic split (5:1:1 ratio)\n",
    "# Train: 50,000 | Val: 10,000 | Test: 10,000 (official test set)\n",
    "train_size = 50000    # 5/6 of training data\n",
    "val_size = 10000      # 1/6 of training data\n",
    "\n",
    "# Split the full training set into train/val subsets\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_train_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(RANDOM_SEED)  # Ensure reproducibility\n",
    ")\n",
    "\n",
    "# Load official test set (10,000 samples)\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=data_dir,\n",
    "    train=False,      # Load test set\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATACH_SIZE,\n",
    "    shuffle=True      # Shuffle training data\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATACH_SIZE,\n",
    "    shuffle=False     # No need to shuffle validation data\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATACH_SIZE,  # Larger batch for evaluation\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Print dataset statistics\n",
    "print(\"Dataset split complete:\")\n",
    "print(f\"Training set: {len(train_dataset)} samples\")\n",
    "print(f\"Validation set: {len(val_dataset)} samples\")\n",
    "print(f\"Test set: {len(test_dataset)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "592989a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas.core.scaling import ScalingImplType\n",
    "import torch\n",
    "\n",
    "\n",
    "total_bits = 8   #width for weights and activations\n",
    "n = 7            #fractional part\n",
    "class LeNet5(Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # Changhong, add input quant layer\n",
    "        # self.quant_input = qnn.QuantIdentity(\n",
    "        #     quant_type=QuantType.INT,\n",
    "        #     bit_width=total_bits,\n",
    "        #     max_val=1.0,  # 假设输入数据已归一化到 [0,1]\n",
    "        #     restrict_scaling_type=RestrictValueType.POWER_OF_TWO,\n",
    "        #     scaling_impl_type=ScalingImplType.CONST\n",
    "        # )\n",
    "        self.quant_input = qnn.QuantIdentity(\n",
    "            quant_type=QuantType.INT,\n",
    "            bit_width=8,\n",
    "            scaling_init=1.0,               # 初始缩放因子\n",
    "            scaling_impl_type=ScalingImplType.PARAMETER,  # 允许训练中调整\n",
    "            scaling_per_output_channel=False,  # 对于单通道输入，通常不需要每个输出通道的缩放\n",
    "            )\n",
    "\n",
    "\n",
    "        self.conv1 = qnn.QuantConv2d(in_channels= 1,\n",
    "                                     out_channels= 20,\n",
    "                                     kernel_size= 3,\n",
    "                                     padding= 1,\n",
    "                                     bias= False,\n",
    "                                     weight_quant_type=QuantType.INT, \n",
    "                                     weight_bit_width= total_bits,\n",
    "                                     weight_restrict_scaling_type=RestrictValueType.POWER_OF_TWO,\n",
    "                                     weight_scaling_impl_type=ScalingImplType.CONST,\n",
    "                                     weight_scaling_const=1.0)\n",
    "        self.relu1 = qnn.QuantReLU(quant_type=QuantType.INT, \n",
    "                                   bit_width=8, \n",
    "                                   max_val= 1- 1/128.0,\n",
    "                                   restrict_scaling_type=RestrictValueType.POWER_OF_TWO,\n",
    "                                   scaling_impl_type=ScalingImplType.CONST )\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "\n",
    "        self.conv2 = qnn.QuantConv2d(in_channels= 20,\n",
    "                                     out_channels= 50,\n",
    "                                     kernel_size= 3,\n",
    "                                     padding= 1,\n",
    "                                     bias= False,\n",
    "                                     weight_quant_type=QuantType.INT, \n",
    "                                     weight_bit_width=8,\n",
    "                                     weight_restrict_scaling_type=RestrictValueType.POWER_OF_TWO,\n",
    "                                     weight_scaling_impl_type=ScalingImplType.CONST,\n",
    "                                     weight_scaling_const=1.0 )\n",
    "\n",
    "        self.relu2 = qnn.QuantReLU(quant_type=QuantType.INT, \n",
    "                                   bit_width=8, \n",
    "                                   max_val= 1- 1/128.0,\n",
    "                                   restrict_scaling_type=RestrictValueType.POWER_OF_TWO,\n",
    "                                   scaling_impl_type=ScalingImplType.CONST )\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        \"\"\"\n",
    "        # for 32-bit precision FC layers\n",
    "        self.fc1   = nn.Linear(7*7*50, 500)\n",
    "\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.fc2   = nn.Linear(500,10)\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        # for fixed-point precision FC layers\n",
    "        self.fc1   = qnn.QuantLinear(7*7*50, 500,\n",
    "                                     bias= True,\n",
    "                                     weight_quant_type=QuantType.INT, \n",
    "                                     weight_bit_width=32,\n",
    "                                     weight_restrict_scaling_type=RestrictValueType.POWER_OF_TWO,\n",
    "                                     weight_scaling_impl_type=ScalingImplType.CONST,\n",
    "                                     weight_scaling_const=1.0)\n",
    "        \n",
    "\n",
    "        self.relu3 = qnn.QuantReLU(quant_type=QuantType.INT, \n",
    "                                   bit_width=8, \n",
    "                                   max_val= 1- 1/128.0,\n",
    "                                   restrict_scaling_type=RestrictValueType.POWER_OF_TWO,\n",
    "                                   scaling_impl_type=ScalingImplType.CONST )\n",
    "\n",
    "        self.fc2   = qnn.QuantLinear(500, 10,\n",
    "                                     bias= True,\n",
    "                                     weight_quant_type=QuantType.INT, \n",
    "                                     weight_bit_width=8,\n",
    "                                     weight_restrict_scaling_type=RestrictValueType.POWER_OF_TWO,\n",
    "                                     weight_scaling_impl_type=ScalingImplType.CONST,\n",
    "                                     weight_scaling_const=1.0)\n",
    "    def forward(self, x):\n",
    "        out = self.quant_input(x)  # Apply input quantization\n",
    "        out = self.relu1(self.conv1(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = self.relu2(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.relu3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2887a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_model(model, train_loader, val_loader, test_loader, num_epochs=10, lr=0.001):\n",
    "    # Initialize device (use GPU if available)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Training phase with progress bar\n",
    "        train_progress = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        for inputs, labels in train_progress:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_progress.set_postfix({\n",
    "                'loss': running_loss/(train_progress.n+1),\n",
    "                'acc': 100.*correct/total\n",
    "            })\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        print(f'Validation - Loss: {val_loss/len(val_loader):.4f}, Acc: {100.*val_correct/val_total:.4f}%')\n",
    "    \n",
    "    # Final test evaluation\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Test Accuracy: {100.*test_correct/test_total:.4f}%')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "950c2f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Train]:   0%|                                                                                                             | 0/391 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:350.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/changhong/prj/finn/deps/brevitas/src/brevitas/nn/quant_linear.py:69: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:350.)\n",
      "  output_tensor = linear(x, quant_weight, quant_bias)\n",
      "Epoch 1/50 [Train]: 100%|█████████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 90.52it/s, loss=0.218, acc=94.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0708, Acc: 97.7600%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 [Train]: 100%|█████████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 93.32it/s, loss=0.052, acc=98.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0460, Acc: 98.5600%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 [Train]: 100%|████████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 90.73it/s, loss=0.0334, acc=99.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0511, Acc: 98.4900%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 [Train]: 100%|█████████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 92.15it/s, loss=0.024, acc=99.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0380, Acc: 98.7900%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 [Train]: 100%|████████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 93.70it/s, loss=0.0167, acc=99.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0311, Acc: 98.9200%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 89.63it/s, loss=0.00962, acc=99.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0285, Acc: 99.1100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 84.11it/s, loss=0.00737, acc=99.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0304, Acc: 98.9800%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 [Train]: 100%|█████████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 92.90it/s, loss=0.005, acc=99.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0278, Acc: 99.1900%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 85.63it/s, loss=0.00348, acc=99.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0298, Acc: 99.1000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 [Train]: 100%|██████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 92.64it/s, loss=0.00282, acc=99.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0264, Acc: 99.2300%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 90.38it/s, loss=0.00199, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0282, Acc: 99.2400%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 89.73it/s, loss=0.00069, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0263, Acc: 99.2500%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 [Train]: 100%|██████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 90.27it/s, loss=0.000362, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0264, Acc: 99.2400%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 [Train]: 100%|██████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 91.28it/s, loss=0.000263, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0271, Acc: 99.2900%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 [Train]: 100%|██████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 91.59it/s, loss=0.000207, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0272, Acc: 99.2500%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 [Train]: 100%|██████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 92.02it/s, loss=0.000158, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0274, Acc: 99.2800%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 [Train]: 100%|██████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 90.10it/s, loss=0.000116, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0276, Acc: 99.2800%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 91.75it/s, loss=9.49e-5, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0280, Acc: 99.2900%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 92.06it/s, loss=7.42e-5, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0280, Acc: 99.3000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 92.06it/s, loss=6.35e-5, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0286, Acc: 99.2900%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 92.21it/s, loss=4.88e-5, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0300, Acc: 99.2500%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 92.87it/s, loss=4.22e-5, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0296, Acc: 99.2700%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 [Train]: 100%|████████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 92.80it/s, loss=3.2e-5, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0297, Acc: 99.2900%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 [Train]: 100%|████████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 92.14it/s, loss=2.8e-5, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0305, Acc: 99.2800%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 92.15it/s, loss=2.14e-5, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0307, Acc: 99.3100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 [Train]: 100%|████████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 92.89it/s, loss=1.8e-5, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0308, Acc: 99.3100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 91.01it/s, loss=1.42e-5, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0308, Acc: 99.2900%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 93.17it/s, loss=1.16e-5, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0314, Acc: 99.2900%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 [Train]: 100%|████████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 93.69it/s, loss=9.7e-6, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0316, Acc: 99.2900%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 90.51it/s, loss=7.75e-6, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0325, Acc: 99.2900%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 93.15it/s, loss=6.27e-6, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0326, Acc: 99.3100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 92.96it/s, loss=5.23e-6, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0334, Acc: 99.3100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 89.93it/s, loss=4.39e-6, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0335, Acc: 99.3000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 93.90it/s, loss=3.64e-6, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0334, Acc: 99.2800%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 91.21it/s, loss=2.94e-6, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0346, Acc: 99.3000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 93.56it/s, loss=2.49e-6, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0346, Acc: 99.3100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 93.02it/s, loss=2.18e-6, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0347, Acc: 99.3200%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 94.30it/s, loss=1.62e-6, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0351, Acc: 99.3100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 92.40it/s, loss=1.26e-6, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0360, Acc: 99.2900%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 [Train]: 100%|██████████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 94.55it/s, loss=1e-6, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0356, Acc: 99.3300%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 93.31it/s, loss=8.43e-7, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0365, Acc: 99.3200%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 92.39it/s, loss=7.03e-7, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0369, Acc: 99.3000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 93.13it/s, loss=5.94e-7, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0373, Acc: 99.3000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 93.40it/s, loss=4.81e-7, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0379, Acc: 99.3100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 92.61it/s, loss=3.86e-7, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0387, Acc: 99.3000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 93.92it/s, loss=3.26e-7, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0387, Acc: 99.3100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 92.69it/s, loss=2.61e-7, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0388, Acc: 99.3300%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 91.97it/s, loss=2.19e-7, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0392, Acc: 99.3200%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 92.66it/s, loss=1.78e-7, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0396, Acc: 99.3100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 [Train]: 100%|███████████████████████████████████████████████████████████████████████████| 391/391 [00:04<00:00, 93.04it/s, loss=1.49e-7, acc=100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.0402, Acc: 99.3200%\n",
      "Test Accuracy: 99.1300%\n"
     ]
    }
   ],
   "source": [
    "model = LeNet5()\n",
    "trained_model = train_model(model, train_loader, val_loader, test_loader, num_epochs=EPOCHS, lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4b286695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model saved to /home/changhong/prj/finn/notebooks/EF-US-Engine-Free-Unstructured-Sparsity-Design-Alleviates-Accelerator-Bottlenecks/casestudy1/LeNet_MNIST/model/lenet_mnist_int8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/changhong/prj/finn/deps/brevitas/src/brevitas/quant_tensor/int_quant_tensor.py:32: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  signed = torch.tensor(signed, dtype=torch.bool)\n",
      "/home/changhong/prj/finn/deps/brevitas/src/brevitas/quant_tensor/int_quant_tensor.py:34: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  training = torch.tensor(training, dtype=torch.bool)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/onnx/_internal/jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model saved to /home/changhong/prj/finn/notebooks/EF-US-Engine-Free-Unstructured-Sparsity-Design-Alleviates-Accelerator-Bottlenecks/casestudy1/LeNet_MNIST/model/lenet_mnist_int8.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at ../torch/csrc/jit/passes/onnx/shape_type_inference.cpp:1884.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    }
   ],
   "source": [
    "# save the trained model weights\n",
    "model_path = os.path.join(model_dir, \"lenet_mnist_int8.pth\")\n",
    "torch.save(trained_model.state_dict(), model_path)\n",
    "print(f\"Trained model saved to {model_path}\")\n",
    "\n",
    "# save the model to ONNX format\n",
    "onnx_model_path = os.path.join(model_dir, \"lenet_mnist_int8.onnx\")\n",
    "\n",
    "# put model back to CPU for ONNX export\n",
    "trained_model.to('cpu')\n",
    "torch.onnx.export(\n",
    "    trained_model,\n",
    "    torch.randn(1, 1, 28, 28),  # Dummy input for ONNX export\n",
    "    onnx_model_path,\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output']\n",
    ")\n",
    "print(f\"ONNX model saved to {onnx_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1ab14961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from brevitas.nn import QuantConv2d, QuantLinear, QuantReLU, QuantIdentity\n",
    "from brevitas.quant import Int8WeightPerTensorFixedPoint, Int8ActPerTensorFixedPoint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import onnx\n",
    "from finn.util.test import get_test_model_trained\n",
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from finn.util.basic import make_build_dir\n",
    "from finn.util.visualization import showInNetron\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "88cc3a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 20 16:52:31 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX 4000 Ada Gene...    Off |   00000000:02:00.0  On |                  Off |\n",
      "| 30%   40C    P8             11W /  130W |    3309MiB /  20475MiB |     37%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "48297cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/changhong/prj/finn/notebooks\n"
     ]
    }
   ],
   "source": [
    "# print current working directory\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5cc6c845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /home/changhong/prj/finn/notebooks/EF-US-Engine-Free-Unstructured-Sparsity-Design-Alleviates-Accelerator-Bottlenecks/casestudy1/LeNet_MNIST_BNN/data\n",
      "Finn root directory: /home/changhong/prj/finn/notebooks\n",
      "Build directory: /home/changhong/prj/finn/notebooks/EF-US-Engine-Free-Unstructured-Sparsity-Design-Alleviates-Accelerator-Bottlenecks/casestudy1/LeNet_MNIST_BNN/build\n",
      "Model directory: /home/changhong/prj/finn/notebooks/EF-US-Engine-Free-Unstructured-Sparsity-Design-Alleviates-Accelerator-Bottlenecks/casestudy1/LeNet_MNIST_BNN/model\n"
     ]
    }
   ],
   "source": [
    "notebook_name = \"/EF-US-Engine-Free-Unstructured-Sparsity-Design-Alleviates-Accelerator-Bottlenecks/casestudy1/LeNet_MNIST_BNN\"\n",
    "finn_root = os.getcwd()\n",
    "build_dir = finn_root+ notebook_name +\"/build\"\n",
    "model_dir = finn_root+ notebook_name +\"/model\"\n",
    "data_dir = finn_root+ notebook_name +\"/data\"\n",
    "\n",
    "# Create directories if they do not exist\n",
    "os.makedirs(build_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Finn root directory: {finn_root}\")\n",
    "print(f\"Build directory: {build_dir}\")\n",
    "print(f\"Model directory: {model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b47a20",
   "metadata": {},
   "source": [
    "# Model define\n",
    "This CNV model is modified from brevitas one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "09a4974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import BatchNorm1d\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import MaxPool2d, AvgPool2d\n",
    "from torch.nn import Module\n",
    "from torch.nn import ModuleList\n",
    "\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas.nn import QuantConv2d\n",
    "from brevitas.nn import QuantIdentity\n",
    "from brevitas.nn import QuantLinear\n",
    "\n",
    "from brevitas_examples.bnn_pynq.models.common import CommonActQuant\n",
    "from brevitas_examples.bnn_pynq.models.common import CommonWeightQuant\n",
    "from brevitas_examples.bnn_pynq.models.tensor_norm import TensorNorm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a3d5a5",
   "metadata": {},
   "source": [
    "# Build a standard CNV 1W1A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2a922e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "# CNV_OUT_CH_POOL = [(64, False), (64, True), (128, False), (128, True), (256, False), (256, False)]\n",
    "# INTERMEDIATE_FC_FEATURES = [(256, 512), (512, 512)]\n",
    "# LAST_FC_IN_FEATURES = 512\n",
    "# LAST_FC_PER_OUT_CH_SCALING = False\n",
    "# POOL_SIZE = 2\n",
    "# KERNEL_SIZE = 3\n",
    "\n",
    "# LeNet-5\n",
    "CNV_OUT_CH_POOL = [(6, True), (16, True), (120, False)]  \n",
    "INTERMEDIATE_FC_FEATURES = [(120, 84)]  \n",
    "LAST_FC_IN_FEATURES = 84 \n",
    "LAST_FC_PER_OUT_CH_SCALING = False\n",
    "POOL_SIZE = 2  \n",
    "KERNEL_SIZE = 5  \n",
    "\n",
    "model_name = '2c3f1w1a_mnist'\n",
    "\n",
    "class CNV(Module):\n",
    "\n",
    "    def __init__(self, num_classes, weight_bit_width, act_bit_width, in_bit_width, in_ch):\n",
    "        super(CNV, self).__init__()\n",
    "\n",
    "        self.conv_features = ModuleList()\n",
    "        self.linear_features = ModuleList()\n",
    "\n",
    "        self.conv_features.append(QuantIdentity( # for Q1.7 input format\n",
    "            act_quant=CommonActQuant,\n",
    "            bit_width=in_bit_width,\n",
    "            min_val=- 1.0,\n",
    "            max_val=1.0 - 2.0 ** (-7),\n",
    "            narrow_range=False,\n",
    "            restrict_scaling_type=RestrictValueType.POWER_OF_TWO))\n",
    "\n",
    "        for out_ch, is_pool_enabled in CNV_OUT_CH_POOL:\n",
    "            self.conv_features.append(\n",
    "                QuantConv2d(\n",
    "                    kernel_size=KERNEL_SIZE,\n",
    "                    in_channels=in_ch,\n",
    "                    out_channels=out_ch,\n",
    "                    bias=False,\n",
    "                    weight_quant=CommonWeightQuant,\n",
    "                    weight_bit_width=weight_bit_width))\n",
    "            in_ch = out_ch\n",
    "            self.conv_features.append(BatchNorm2d(in_ch, eps=1e-4))\n",
    "            self.conv_features.append(\n",
    "                QuantIdentity(act_quant=CommonActQuant, bit_width=act_bit_width))\n",
    "            if is_pool_enabled:\n",
    "                #self.conv_features.append(MaxPool2d(kernel_size=2))\n",
    "                self.conv_features.append(AvgPool2d(kernel_size=2))\n",
    "\n",
    "        for in_features, out_features in INTERMEDIATE_FC_FEATURES:\n",
    "            self.linear_features.append(\n",
    "                QuantLinear(\n",
    "                    in_features=in_features,\n",
    "                    out_features=out_features,\n",
    "                    bias=False,\n",
    "                    weight_quant=CommonWeightQuant,\n",
    "                    weight_bit_width=weight_bit_width))\n",
    "            self.linear_features.append(BatchNorm1d(out_features, eps=1e-4))\n",
    "            self.linear_features.append(\n",
    "                QuantIdentity(act_quant=CommonActQuant, bit_width=act_bit_width))\n",
    "\n",
    "        self.linear_features.append(\n",
    "            QuantLinear(\n",
    "                in_features=LAST_FC_IN_FEATURES,\n",
    "                out_features=num_classes,\n",
    "                bias=False,\n",
    "                weight_quant=CommonWeightQuant,\n",
    "                weight_bit_width=weight_bit_width))\n",
    "        self.linear_features.append(TensorNorm())\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, QuantConv2d) or isinstance(m, QuantLinear):\n",
    "                torch.nn.init.uniform_(m.weight.data, -1, 1)\n",
    "\n",
    "    def clip_weights(self, min_val, max_val):\n",
    "        for mod in self.conv_features:\n",
    "            if isinstance(mod, QuantConv2d):\n",
    "                mod.weight.data.clamp_(min_val, max_val)\n",
    "        for mod in self.linear_features:\n",
    "            if isinstance(mod, QuantLinear):\n",
    "                mod.weight.data.clamp_(min_val, max_val)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = 2.0 * x - torch.tensor([1.0], device=x.device)\n",
    "        for mod in self.conv_features:\n",
    "            x = mod(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        for mod in self.linear_features:\n",
    "            x = mod(x)\n",
    "        return x \n",
    "\n",
    "\n",
    "def cnv(cfg):\n",
    "    weight_bit_width = cfg.getint('QUANT', 'WEIGHT_BIT_WIDTH')\n",
    "    act_bit_width = cfg.getint('QUANT', 'ACT_BIT_WIDTH')\n",
    "    in_bit_width = cfg.getint('QUANT', 'IN_BIT_WIDTH')\n",
    "    num_classes = cfg.getint('MODEL', 'NUM_CLASSES')\n",
    "    in_channels = cfg.getint('MODEL', 'IN_CHANNELS')\n",
    "    net = CNV(\n",
    "        weight_bit_width=weight_bit_width,\n",
    "        act_bit_width=act_bit_width,\n",
    "        in_bit_width=in_bit_width,\n",
    "        num_classes=num_classes,\n",
    "        in_ch=in_channels)\n",
    "    return net\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config['MODEL'] = {\n",
    "    'NUM_CLASSES': '10',\n",
    "    'IN_CHANNELS': '1',\n",
    "    'DTASET': 'MNIST',\n",
    "}\n",
    "config['QUANT'] = {\n",
    "    'WEIGHT_BIT_WIDTH': '1',\n",
    "    'ACT_BIT_WIDTH': '1',\n",
    "    'IN_BIT_WIDTH': '8',\n",
    "}\n",
    "\n",
    "model = cnv(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b2510640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model to ONNX format\n",
    "onnx_model_path = model_dir + f\"/{model_name}.onnx\"\n",
    "# torch.onnx.export(cfg_6c3f_1w1a_minst, \n",
    "#                   torch.randn(1, 1, 32, 32), \n",
    "#                   onnx_model_path, \n",
    "#                   input_names=['input'], \n",
    "#                   output_names=['output'], \n",
    "#                   dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})\n",
    "\n",
    "\n",
    "export_qonnx(model, torch.randn(1, 1, 32, 32), onnx_model_path)\n",
    "qonnx_cleanup(onnx_model_path, out_file=onnx_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4360ded0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split complete:\n",
      "Training set: 48000 samples\n",
      "Validation set: 12000 samples\n",
      "Test set: 10000 samples\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "             transforms.RandomCrop(32, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "\n",
    "full_train_set = datasets.MNIST(data_dir, train=True, download=True, transform=transform)\n",
    "train_size = int(0.8 * len(full_train_set))\n",
    "val_size = len(full_train_set) - train_size\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(full_train_set, [train_size, val_size])\n",
    "test_set = datasets.MNIST(data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "val_loader = DataLoader(val_set, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"Dataset split complete:\")\n",
    "print(f\"Training set: {len(train_set)} samples\")\n",
    "print(f\"Validation set: {len(val_set)} samples\")\n",
    "print(f\"Test set: {len(test_set)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ec4042a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_loss = running_loss / len(loader)\n",
    "    train_acc = 100 * correct / total\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss = running_loss / len(loader)\n",
    "    val_acc = 100 * correct / total\n",
    "    return val_loss, val_acc\n",
    "\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_acc = 100 * correct / total\n",
    "    return test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c980615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:350.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/changhong/prj/finn/deps/brevitas/src/brevitas/nn/quant_linear.py:69: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:350.)\n",
      "  output_tensor = linear(x, quant_weight, quant_bias)\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "num_epochs = 500\n",
    "\n",
    "# 选择一种学习率调度策略\n",
    "# 1. 阶梯式下降\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "# 2. 指数衰减\n",
    "# scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "# 3. 余弦退火\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "# 4. 带热重启的余弦退火\n",
    "# scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=50, T_mult=1)\n",
    "\n",
    "# 5. 根据指标降低学习率（如验证集loss不再下降时）\n",
    "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=10, verbose=True)\n",
    "\n",
    "\n",
    "best_val_acc = 0.0\n",
    "\n",
    "model_save_path = model_dir + f\"/{model_name}.pth\"\n",
    "best_model_save_path = model_dir + f\"/best_{model_name}.pth\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    if hasattr(model, 'clip_weights'):\n",
    "        model.clip_weights(-1.0, 1.0)\n",
    "\n",
    "    # 打印当前学习率\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'LR: {current_lr:.6f}, '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    # 根据验证集准确率调整学习率（对于ReduceLROnPlateau）\n",
    "    scheduler.step(val_acc)  # 如果是其他调度器，直接使用 scheduler.step()\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_save_path)\n",
    "\n",
    "# 测试最佳模型\n",
    "model.load_state_dict(torch.load(best_model_save_path))\n",
    "test_acc = test(model, test_loader, device)\n",
    "print(f'Test Accuracy of the best model on the test images: {test_acc:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
